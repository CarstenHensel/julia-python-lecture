{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc5c54b5",
   "metadata": {},
   "source": [
    "![](Images/p14.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018ebd73",
   "metadata": {},
   "source": [
    "![](Images/p15.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287f23bf",
   "metadata": {},
   "source": [
    "![](Images/p16.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268b661f",
   "metadata": {},
   "source": [
    "![](Images/p17.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb9f62a",
   "metadata": {},
   "source": [
    "![](Images/p18.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72567f0b",
   "metadata": {},
   "source": [
    "![](Images/p19.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0662494-cbcc-430f-a3bb-69e441c594ce",
   "metadata": {},
   "source": [
    "# Python ML Example with Keras\n",
    "(based on https://elitedatascience.com/keras-tutorial-deep-learning-in-python)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45cf697-0e53-46af-a6ea-199f72004263",
   "metadata": {},
   "source": [
    "### What we can't offer in this tutorial..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fad8720-6bb7-40a4-8dd2-4170c320897f",
   "metadata": {},
   "source": [
    "- This is not a complete course on deep learning.\n",
    "- Instead, this tutorial is meant to get you from zero to your first Convolutional Neural Network with as little headache as possible!\n",
    "- It demonstrates the power of Python and serves as an use case example for Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3884101-f102-4efe-9b20-bbe7c5321e95",
   "metadata": {},
   "source": [
    "### Why Keras?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e45c158-2363-4d2e-bbb1-b04bb9ab6755",
   "metadata": {},
   "source": [
    "- Keras recommended library for deep learning in Python, especially for beginners. - Its minimalistic, modular approach makes it a breeze to get deep neural networks up and running.\n",
    "- You can read more about it here:\n",
    "\n",
    "https://elitedatascience.com/python-deep-learning-libraries#keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc91a72e-962d-4012-9bb3-545ef69452c7",
   "metadata": {},
   "source": [
    "### What is Deep Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cfcadf",
   "metadata": {},
   "source": [
    "- First, we have to talk about neurons, the basic unit of a neural network. \n",
    "- A neuron takes inputs, does some math with them, and produces one output. \n",
    "- Here’s what a 2-input neuron looks like:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27542b96",
   "metadata": {},
   "source": [
    "![](Images/neuron.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb5b092",
   "metadata": {},
   "source": [
    "3 things are happening here. First, each input is multiplied by a weight:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44525fe0",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{eqnarray}\n",
    "x_1 &\\to& x_1 \\times w_1\\\\\n",
    "x_2 &\\to& x_2 \\times w_2\n",
    "\\end{eqnarray}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa23bb8",
   "metadata": {},
   "source": [
    "Next, all the weighted inputs are added together with a bias $b$.\n",
    "\n",
    "Finally, the sum is passed through an activation function:\n",
    "\n",
    "The activation function is used to turn an unbounded input into an output that has a nice, predictable form. A commonly used activation function is the sigmoid function:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9bc34d",
   "metadata": {},
   "source": [
    "![](Images/sigmoid.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ed89a9",
   "metadata": {},
   "source": [
    "Estimating the $w_i$ is called **training**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b309ab50",
   "metadata": {},
   "source": [
    "Usually one neuron in one layer is not enough for complex tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212ae0d3-c648-441d-b70e-16f5f205780a",
   "metadata": {},
   "source": [
    "- **Deep learning** refers to neural networks with multiple hidden layers that can learn increasingly abstract representations of the input data.\n",
    "    - This is obviously an oversimplification, but it’s a practical definition for us right now.\n",
    "\n",
    "- For example, deep learning has led to major advances in computer vision.\n",
    "- We’re now able to classify images, find objects in them, and even label them with captions.\n",
    "- To do so, deep neural networks with many hidden layers can sequentially learn more complex features from the raw input image:\n",
    "    - The first hidden layers might only learn local edge patterns.\n",
    "    - Then, each subsequent layer (or filter) learns more complex representations.\n",
    "    - Finally, the last layer can classify the image as a cat or kangaroo.\n",
    "- These types of deep neural networks are called **Convolutional Neural Networks**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dbe938",
   "metadata": {},
   "source": [
    "![](Images/neural_net2.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9448fd5f-9d05-4901-8321-a649b34e411b",
   "metadata": {},
   "source": [
    "### What are Convolutional Neural Networks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e61c50-107f-49d3-b5ce-d051f70cda37",
   "metadata": {},
   "source": [
    "- Convolutional Neural Networks (CNN’s) are multi-layer neural networks (sometimes up to 17 or more layers) that assume the input data to be images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bd50c0",
   "metadata": {},
   "source": [
    "![](Images/neural_net2.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37069948",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e56e22ca-7f31-4053-99a0-851e0da96f4d",
   "metadata": {},
   "source": [
    "![](Images/typical_cnn_architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90966227-bf16-4566-8e3e-64d430f890c8",
   "metadata": {},
   "source": [
    "- By making this requirement, CNN’s can drastically reduce the number of parameters that need to be tuned.\n",
    "- Therefore, CNN’s can efficiently handle the high dimensionality of raw images.\n",
    "\n",
    "- Their underlying mechanics are beyond the scope of this tutorial.\n",
    "  (https://cs231n.github.io/convolutional-networks/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7e090d-2b8d-416c-93d9-05065b2afc1a",
   "metadata": {},
   "source": [
    "# 8 Steps towards a first CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e222ee8-5f63-406e-9cb3-bc682d1774e3",
   "metadata": {},
   "source": [
    "### Step 1: Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe392f8-b8e4-46e2-b831-b4486f0aa874",
   "metadata": {},
   "source": [
    "- Let’s start by importing matplotlib and numpy. \n",
    "- Then set a seed for the computer’s pseudorandom number generator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccada2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03279eac-da54-470c-b165-1f0a977da88d",
   "metadata": {},
   "source": [
    "- Next, we’ll import the Sequential model type from Keras.\n",
    "- This is simply a linear stack of neural network layers.\n",
    "- It’s perfect for the type of feed-forward CNN we’re building in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1482b696",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72376c1-4989-4229-9654-43303f8755ed",
   "metadata": {},
   "source": [
    "- Next, let’s import the “core” layers from Keras.\n",
    "- These are the layers that are used in almost any neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d2e0f9-611a-4867-ab11-cf18a106bcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Activation, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee1db5a-f0e0-46a9-9de7-e5d4d407943f",
   "metadata": {},
   "source": [
    "- Then, we’ll import the CNN layers from Keras.\n",
    "- These are the convolutional layers that will help us efficiently train on image data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e438d4d-43bb-4469-9d24-15d2ea5e46de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Convolution2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ba2b35-a842-45c2-9843-056b719e15b5",
   "metadata": {},
   "source": [
    "- Finally, we’ll import some utilities. This will help us transform our data later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1c0505-dcc8-4d67-bae9-80dc5f6bc6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b9c068-12bc-4ce6-8adf-051079baafb0",
   "metadata": {},
   "source": [
    "### Step 2: Load image data from MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2957bb4-e469-41ba-a4e7-2771e1f560a3",
   "metadata": {},
   "source": [
    "- MNIST is a great dataset for getting started with deep learning and computer vision.\n",
    "- It’s a big enough challenge to warrant neural networks, but it’s manageable on a single computer.\n",
    "- That makes it perfect for this Keras tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eab9637-01c9-4c8f-938d-a82fc38fb42c",
   "metadata": {},
   "source": [
    "- The Keras library conveniently includes it already. We can load it like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a9b4ea-0f3a-42c3-ac7b-49b42418cb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    " \n",
    "# Load pre-shuffled MNIST data into train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58ac2db",
   "metadata": {},
   "source": [
    "- What shape does the dataset have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0416e7-2e12-4a6b-8816-cee0fd4de818",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( X_train.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2789412",
   "metadata": {},
   "source": [
    "- 60000 entries \n",
    "- each one is a 28x28 pixel picture\n",
    "- Let's have a look at a few:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a015b93e-fa64-4999-8d53-b977bba20b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f252c359",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa10053b-5811-4287-b6be-cd3569fbae6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d33ddab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9c5a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245edd72",
   "metadata": {},
   "source": [
    "### Step 3: Preprocess input data for Keras.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569bb92e",
   "metadata": {},
   "source": [
    "- When using the TensorFlow backend, you must explicitly declare a dimension for the number of channels in the input images. \n",
    "    - For example, a full-color image with all 3 RGB channels will have a channel value of 3.\n",
    "\n",
    "- Our MNIST images only have 1 channel, but we must explicitly declare that.\n",
    "\n",
    "- **We want to transform our dataset from having shape (n, width, height) to (n, width, height, channels).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b010a8b-742c-4890-927e-0f6ccd96646b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6da53e5",
   "metadata": {},
   "source": [
    "- To confirm, we can print X_train’s dimensions again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73e43c1-5cc9-4558-a336-c0ea40369792",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( X_train.shape )\n",
    "# (60000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859932ee",
   "metadata": {},
   "source": [
    "- The final preprocessing step for the input data is to convert our data type to float32 and normalize our data values to the range [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e34ec7-26e1-4f58-bedf-fd82a08d18d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591d0ad4",
   "metadata": {},
   "source": [
    "Now, our input data are ready for model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1a116e",
   "metadata": {},
   "source": [
    "### Step 4: Preprocess class labels for Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b793b1f",
   "metadata": {},
   "source": [
    "- Class labels are basically the \"true values\".\n",
    "- Let’s take a look at the shape of our class label data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d4995e-911e-457e-bd9b-3b5087828d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( y_train.shape )\n",
    "# (60000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04eaf59-72ef-49f4-b275-77574a1d2152",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0], y_train[1], y_train[2], y_train[3], y_train[4], "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7c3df6",
   "metadata": {},
   "source": [
    "- We should have 10 different classes, one for each digit. \n",
    "- But it looks like we only have a 1-dimensional array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f048073d",
   "metadata": {},
   "source": [
    "- This can be easily fixed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1916e268-b5a5-4ac0-af23-613e6ec6edd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e53b053",
   "metadata": {},
   "source": [
    "- Now we can take another look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6cc0ce-7b32-4bd0-959b-8c8db6784cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( Y_train.shape )\n",
    "# (60000, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f747bb24",
   "metadata": {},
   "source": [
    "- That looks much better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a970399",
   "metadata": {},
   "source": [
    "### Step 5: Define model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15cc5a0",
   "metadata": {},
   "source": [
    "- Now we’re ready to define our model architecture. \n",
    "    - How many layers? What kind of layers? ...\n",
    "- In actual R&D work, researchers will spend a considerable amount of time studying model architectures.\n",
    "\n",
    "- We don't have the time to re-do the architecture analysis.\n",
    "- We'll provide the actual architecture.\n",
    "\n",
    "- Let’s start by declaring a sequential model format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c389a9d0-1072-4918-a0eb-db73c90e1209",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d390f6b",
   "metadata": {},
   "source": [
    "- Next, we declare the input layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e266fe-8f8f-43ae-a3cc-ebc7648bcab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Convolution2D(32, (3,3), activation='relu', input_shape=(28,28,1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5938581",
   "metadata": {},
   "source": [
    "- The input shape parameter should be the shape of 1 sample. \n",
    "- In this case, it’s the same (28, 28, 1) that corresponds to the (width, height, channels) of each digit image.\n",
    "\n",
    "- But what do the first two parameters represent? \n",
    "- They correspond to the number of convolution filters to use (32) and the number of rows and columns (3, 3) in each convolution kernel.\n",
    "\n",
    "    - Note: The step size is (1,1) by default, and it can be tuned using the ‘strides‘ parameter.\n",
    "\n",
    "- We can confirm this by printing the shape of the current model output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b721e1eb-c333-4df2-8725-0242ac4c1b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( model.output_shape )\n",
    "# (None, 26, 26, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1371008",
   "metadata": {},
   "source": [
    "- That output corresponds to (samples, new_rows, new_cols, filters). \n",
    "- In other words, the current model will output all of the samples, convoluted into a 26×26 array using 32 filters.\n",
    "---\n",
    "- Next, we can simply add more layers to our model like we’re building legos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2cf37b-632e-47fd-be13-8adb781814bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Convolution2D(32, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003961c8",
   "metadata": {},
   "source": [
    "- Again, we won’t go into the theory too much, but it’s important to highlight the Dropout layer we just added: \n",
    "    - This is a method for regularizing our model in order to prevent **overfitting**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b639eff5",
   "metadata": {},
   "source": [
    "![](Images/dropout.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ddaf75",
   "metadata": {},
   "source": [
    "![](Images/overfitting.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46286db6",
   "metadata": {},
   "source": [
    "- '''MaxPooling2D''' is a way to reduce the number of parameters in our model by sliding a 2×2 pooling filter across the previous layer and taking the max of the 4 values in the 2×2 filter.\n",
    "\n",
    "- So far, for model parameters, we’ve added two Convolution layers. \n",
    "- To complete our model architecture, let’s add a **fully connected** layer and then the output layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb06aba-6100-4c40-98a4-9061275311dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3cb418",
   "metadata": {},
   "source": [
    "- For **Dense layers**, the first parameter is the output size of the layer. Keras automatically handles the connections between layers.\n",
    "\n",
    "- Note that the final layer has an output size of 10, corresponding to the 10 classes of digits.\n",
    "\n",
    "- Also note that the weights from the Convolution layers must be flattened (made 1-dimensional) before passing them to the fully connected Dense layer.\n",
    "- ReLU is defined as\n",
    "$$\n",
    "\\mathrm{ReLU}(x) = \\max(0,x)\n",
    "$$\n",
    "- Softmax is defined as\n",
    "\n",
    "$$\n",
    "\\mathrm{softmax}(x_i) = \\dfrac{\\exp{x_i}}{\\sum_j \\exp{x_j}}\\in[0..1]\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "- Now all we need to do is define the loss function and the optimizer, and then we’ll be ready to train it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74769b56",
   "metadata": {},
   "source": [
    "### Step 6: Compile model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c09d12",
   "metadata": {},
   "source": [
    "- Almost done!\n",
    "- We just need to compile the model and we’ll be ready to train it. \n",
    "- When we **compile** the model, we declare the loss function and the optimizer (SGD, Adam, etc.).\n",
    "- N.B. Keras has a variety of loss functions and out-of-the-box optimizers to choose from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6556522b-2a94-4f5f-aac1-87a0ee14c625",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb02326",
   "metadata": {},
   "source": [
    "### Step 7: Fit model on training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c36ca9d",
   "metadata": {},
   "source": [
    "- To fit the model, all we have to do is declare the batch size and number of epochs to train for, then pass in our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e1e3fc-0173-4da4-ada8-1fb113aef8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = model.fit(X_train, Y_train, \n",
    "          batch_size=32, epochs=2, verbose=1) # epochs 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fc18a0",
   "metadata": {},
   "source": [
    "### Step 8: Evaluate model on test data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3885891",
   "metadata": {},
   "source": [
    "- Finally, we can evaluate our model on the test data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46de18e5-3d04-4053-ab5c-e6353fe6dc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd1b775-3804-4039-a9be-66395e622320",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test loss:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191709df",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train.history['loss'], label='train')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss values')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580359bf-9f9f-413d-beab-daecd4d6a741",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train.history['accuracy'], label='test')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy values')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1108cd2",
   "metadata": {},
   "source": [
    "#### Model Loss\n",
    "![](Images/loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363235f1",
   "metadata": {},
   "source": [
    "#### Model Accuracy\n",
    "![](Images/Accuracy.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217f155e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
